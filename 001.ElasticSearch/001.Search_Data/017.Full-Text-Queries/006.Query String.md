# Simple query string query
Returns documents based on a provided query string, using a parser with a strict syntax.(使用具有严格语法的解析器，根据提供的查询字符串返回文档。)

This query uses a [syntax](#query-string-syntax) to parse and split the provided query string based on operators, such as AND or NOT. The query then analyzes each split text independently before returning matching documents.(此查询使用一种语法根据运算符（如and或NOT）解析和拆分提供的查询字符串。然后，查询在返回匹配的文档之前独立分析每个分割文本。)

You can use the query_string query to create a complex search that includes wildcard characters, searches across multiple fields, and more. While versatile, the query is strict and returns an error if the query string includes any invalid syntax.(您可以使用query_string查询创建复杂的搜索，其中包括通配符、跨多个字段的搜索等。虽然功能多样，但查询是严格的，如果查询字符串包含任何无效语法，则返回错误。)

Because it returns an error for any invalid syntax, we don’t recommend using the query_string query for search boxes.(因为任何无效语法都会返回错误，所以我们不建议对搜索框使用query_string查询。)

## Example request
When running the following search, the query_string query splits (new york
city) OR (big apple) into two parts: new york city and big apple. The content field’s analyzer then independently converts each part into tokens before returning matching documents. Because the query syntax does not use whitespace as an operator, new york city is passed as-is to the analyzer.(运行以下搜索时，query_string查询会拆分(new york
city) OR (big apple)分为两部分：new york city 和 big apple。然后，内容字段的分析器在返回匹配的文档之前，将每个部分独立地转换为tokens。由于查询语法不使用空格作为运算符，因此将new york city原样传递给**分析器**。)
```txt
   GET /_search
   {
     "query": {
       "query_string": {
         "query": "(new york city) OR (big apple)",
         "default_field": "content"
       }
     }
   }
```

## Top-level parameters for query_string
+ query
  - (Required, string) Query string you wish to parse and use for search
+ default_field
  - (Optional, string) Default field to search if no field is provided in the query string. Supports wildcards (\*).（（可选，字符串）如果查询字符串中没有提供字段，则搜索默认字段。支持通配符（\*）。）
  - Defaults to the index.query.default_field index setting, which has a default value of *. The * value extracts all fields that are eligible for term queries and filters the metadata fields. All extracted fields are then combined to build a query if no prefix is specified.
  - Searching across all eligible fields does not include nested documents. Use a [nested query](../019.Joining%20Queries/000.Nested%20Query.md) to search those documents.
  - For mappings with a large number of fields, searching across all eligible fields could be expensive.
  - There is a limit on the number of fields times terms that can be queried at once. It is defined by the indices.query.bool.max_clause_count search setting.
+ allow_leading_wildcard
  - (Optional, Boolean) If true, the wildcard characters * and ? are allowed as the first character of the query string. Defaults to true.
+ analyze_wildcard
  - (Optional, Boolean) If true, the query attempts to analyze wildcard terms in the query string. Defaults to false.(（可选，布尔值）如果为true，则查询将尝试分析查询字符串中的通配符。默认为false。)
+ analyzer
  - (Optional, string) Analyzer used to convert text in the query string into tokens. Defaults to the index-time analyzer mapped for the default_field. If no analyzer is mapped, the index’s default analyzer is used.
+ auto_generate_synonyms_phrase_query
  - If true, match phrase queries are automatically created for multi-term synonyms(同义词). Defaults to true. See [Synonyms and the query_string query](#synonyms-and-the-query_string-query) for an example.

+ default_operator
  - Default boolean logic used to interpret text in the query string if no operators are specified. Valid values are:
    + OR (Default)
      - For example, a query string of capital of Hungary is interpreted as capital OR of OR Hungary.
    + AND
      - For example, a query string of capital of Hungary is interpreted as capital
AND of AND Hungary.

+ fields
  - (Optional, array of strings) Array of fields to search. Supports wildcards (*).
  -  You can use this parameter query to search across multiple fields

+ fuzziness
  - Maximum edit distance allowed for fuzzy matching. For fuzzy syntax, see [Fuzziness](#fuzziness).

+ fuzzy_max_expansions
  - Maximum number of terms to which the query expands for fuzzy matching. Defaults to 50.

+ fuzzy_prefix_length
  - Number of beginning characters left unchanged for fuzzy matching. Defaults to 0

+ fuzzy_transpositions
  - If true, edits for fuzzy matching include transpositions of two adjacent characters (ab → ba). Defaults to true.(如果为真，则模糊匹配的编辑包括两个相邻字符的转置（ab→ba）。默认为true。)

+ lenient
  -  If true, format-based errors, such as providing a text value for a numeric field, are ignored. Defaults to false.(如果为true，则忽略基于格式的错误，例如为数字字段提供文本值。默认为false。)

+ minimum_should_match
  - Minimum number of clauses that must match for a document to be returned. 

+ quote_analyzer
  - [Analyzer](../../005.Text%20analysis/README.md) used to convert quoted text in the query string into tokens. Defaults to the [search_quote_analyzer](../../05A.Mapping/001.Mapping%20parameters/000.analyzer.md) mapped for the default_field.
+ phrase_slop
  - Maximum number of positions allowed between matching tokens for phrases. Defaults to 0. If 0, exact phrase matches are required. Transposed terms have a slop of 2
+ rewrite
  - Method used to rewrite the query. For valid values and more information, see the [rewrite parameter](../020.rewrite%20parameter.md).
+ time_zone
  -  Coordinated Universal Time (UTC) offset or IANA time zone used to convert date values in the query string to UTC.
  - Valid values are ISO 8601 UTC offsets, such as +01:00 or -08:00, and IANA time zone IDs, such as America/Los_Angeles.
  - The time_zone parameter does not affect the date math value of now. now is always the current system time in UTC. However, the time_zone parameter does convert dates calculated using now and date math rounding. For example, the time_zone parameter will convert a value of now/d.

## Query string syntax
The query string is parsed into a series of terms and operators. A term can be a single word — quick or brown — or a phrase, surrounded by double quotes — "quick brown" — which searches for all the words in the phrase, in the same order.(查询字符串被解析为一系列术语和运算符。一个词可以是一个单词-quick或brown或者是一个被双引号括起来的短语——“quick brown”——它以相同的顺序搜索短语中的所有单词。)

Operators allow you to customize the search — the available options are explained below.(操作员允许您自定义搜索——下面解释了可用的选项。)

### Field names
You can specify fields to search in the query syntax:
1. where the status field contains active
   ```txt
      status:active
   ```
2. where the title field contains quick or brown
   ```txt
      title:(quick OR brown)
   ```
3. where the author field contains the exact phrase "john smith"
   ```txt
      author:"John Smith"
   ```
4. where the first name field contains Alice (note how we need to escape the space with a backslash) (其中名字字段包含Alice（注意我们需要用反斜杠转义空格）)
   ```txt
      first\ name:Alice
   ```
5. where any of the fields book.title, book.content or book.date contains quick or brown (note how we need to escape the * with a backslash):(其中任何字段book.title、book.content或book.date包含quick或brown（注意我们需要用反斜杠转义*）)
   ```txt
     book.\*:(quick OR brown)
   ```
6. where the field title has any non-null value:
   ```txt
      _exists_:title
   ```

## Wildcards
Wildcard searches can be run on individual terms, using ? to replace a single character, and * to replace zero or more characters:(通配符搜索可以在单个术语上运行，使用？替换单个字符，*替换零个或多个字符：)
```txt
  qu?ck bro*
```
Be aware that wildcard queries can use an enormous amount of memory and perform very badly — just think how many terms need to be queried to match the query string "a* b* c*".(请注意，通配符查询可能会使用大量内存，并且性能非常差——想想需要查询多少术语才能匹配查询字符串“a*b*c*”。)

Only parts of the analysis chain that operate at the character level are applied. So for instance, if the analyzer performs both lowercasing and stemming, only the lowercasing will be applied: it would be wrong to perform stemming on a word that is missing some of its letters.(仅应用在字符级别运行的分析链部分。因此，例如，如果分析器同时执行小写和词干分析，则只应用小写：对缺少部分字母的单词执行词干分析是错误的。)

By setting analyze_wildcard to true, queries that end with a * will be analyzed and a boolean query will be built out of the different tokens, by ensuring exact matches on the first N-1 tokens, and prefix match on the last token.(通过将analyze_wildcard设置为true，将分析以*结尾的查询，并通过确保前N-1个令牌的精确匹配和最后一个令牌的前缀匹配，从不同的令牌中构建布尔查询。)


## Regular expressions（正则表达式）
Regular expression patterns can be embedded in the query string by wrapping them in forward-slashes ("/"):（正则表达式模式可以通过用正斜杠（“/”）括起来嵌入查询字符串中：）
```txt
   name:/joh?n(ath[oa]n)/
```

The supported regular expression syntax is explained in [Regular expression syntax](https://www.elastic.co/guide/en/elasticsearch/reference/current/regexp-syntax.html).

## Synonyms and the query_string query
The query_string query supports multi-terms synonym expansion with the synonym_graph token filter. When this filter is used, the parser creates a phrase query for each multi-terms synonyms. For example, the following synonym: ny, new york would produce: （query_string查询支持使用synonym_graph标记过滤器进行多术语同义词扩展。当使用此过滤器时，解析器会为每个多术语同义词创建一个短语查询。例如，以下同义词：ny，new york将产生：）
```txt
   (ny OR ("new york"))
```
It is also possible to match multi terms synonyms with conjunctions instead:(也可以将多个术语的同义词与连词进行匹配：)
```txt
    GET /_search
    {
       "query": {
           "query_string" : {
               "default_field": "title",
               "query" : "ny city",
               "auto_generate_synonyms_phrase_query" : false
           }
       }
    }
```
The example above creates a boolean query:
```txt
   (ny OR (new AND york)) city
```

that matches documents with the term ny or the conjunction new AND york. By default the parameter auto_generate_synonyms_phrase_query is set to true.(将文档与术语ny或连词new AND york匹配。默认情况下，参数auto_generate_synonyms_frasse_query设置为true。)

## fuzziness(模糊性)
You can run [fuzzy queries](https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-fuzzy-query.html) using the ~ operator:

```txt
quikc~ brwn~ foks~
```

The default edit distance is 2, but an edit distance of 1 should be sufficient to catch 80% of all human misspellings. It can be specified as:(默认的编辑距离为2，但1的编辑距离应该足以捕捉到80%的人为拼写错误。可以指定为：)
```txt
quikc~1
```

## 参考资料
1. [Simple query string query](https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-simple-query-string-query.html)