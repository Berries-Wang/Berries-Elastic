# ElasticSearch 深度分页问题
ElasticSearch 深度分页问题主要与分页查询有关，在分页查询时，每次都需要对所有数据进行查询，然后取出指定范围内的文档，这回导致效率低下和资源浪费。

|分页方式|使用场景|
|---|---|
|from + size|对于数据量较小(from+size 在10000条以内)的情况，或者还需要关注结果集前几条数据，可以使用from + size方式|
|scroll方式|对于数据量大且需要深度分页的情况，如 后台批处理任务（数据迁移）。scroll API能够高效地获取大量，并且避免了对全部数据的排序操作，提高了查询效率|
|search after|对于数据量大且需要深度翻页，同时存在用户实时、高并发查询需求的情况。search after能够提供一种高效的、可拓展的、适用于大规模数据的分页查询操作，同时还能满足实时查询的需求。|

---

## 分页方式内部处理方式
### scroll方式
> Elasticsearch 的 scroll 方式分页不会对数据加锁。scroll 主要用于处理大量数据的遍历，它通过创建一个快照来确保在遍历过程中数据的一致性，但不会锁定数据。因此，需要维护一个上下文，这是一种开销；且在使用完成后，需要 `clear scroll`(程序异常咋办),否则一直会占用系统资源。

> [官方文档](https://www.elastic.co/guide/en/elasticsearch/reference/current/scroll-api.html): We no longer recommend using the scroll API for deep pagination. If you need to preserve the index state while paging through more than 10,000 hits, use the search_after parameter with a point in time (PIT).(我们不再建议使用scroll API进行深度分页。如果需要在分页超过10,000个命中时保留索引状态，则使用search_after参数和时间点（PIT）。)

- Scrolling is not intended for real time user requests, but rather for processing large amounts of data, e.g. in order to reindex the contents of one data stream or index into a new data stream or index with a different configuration.(滚动不是为了实时用户请求，而是为了处理大量数据，例如，为了将一个数据流或索引的内容重新索引为具有不同配置的新数据流或索引。)

#### Keeping the search context alive
A scroll returns all the documents which matched the search at the time of the initial search request. It ignores any subsequent changes to these documents. The scroll_id identifies a search context which keeps track of everything that Elasticsearch needs to return the correct documents. The search context is created by the initial request and kept alive by subsequent requests.（滚动返回在初始搜索请求时与搜索匹配的所有文档。它`将忽略对这些文档的任何后续更改`。scroll_id标识一个搜索上下文，该上下文跟踪 Elasticsearch 返回正确文档所需的一切。搜索上下文由初始请求创建，并由后续请求保持活动状态。）


The scroll parameter (passed to the search request and to every scroll request) tells Elasticsearch how long it should keep the search context alive. Its value (e.g. 1m, see Time units) does not need to be long enough to process all data — it just needs to be long enough to process the previous batch of results. Each scroll request (with the scroll parameter) sets a new expiry time. If a scroll request doesn’t pass in the scroll parameter, then the search context will be freed as part of that scroll request.（scroll 参数（传递给搜索请求和每个滚动 request） 告诉 Elasticsearch 它应该让搜索上下文保持活动状态多长时间。 它的值（例如 1m，参见 Time units）不需要足够长的时间来处理所有数据——它只需要足够长的时间来处理前一批结果。每个 scroll 请求（使用 scroll 参数）都会设置一个新的到期时间。如果滚动请求未传入滚动 参数，则搜索上下文将作为该滚动的一部分被释放 请求。）

Normally, the background merge process optimizes the index by merging together smaller segments to create new, bigger segments. Once the smaller segments are no longer needed they are deleted. This process continues during scrolling, but an open search context prevents the old segments from being deleted since they are still in use.（通常，后台合并过程通过将较小的段合并在一起来创建新的、更大的段来优化索引。一旦不再需要较小的区段，它们就会被删除。此过程在滚动期间继续，但打开的搜索上下文会阻止删除旧区段，因为它们仍在使用中。）

#### Clear scroll  清除滚动
Search context are automatically removed when the scroll timeout has been exceeded. However keeping scrolls open has a cost, as discussed in the previous section so scrolls should be explicitly cleared as soon as the scroll is not being used anymore using the clear-scroll API:(当滚动超时时，会自动删除搜索上下文 超过。但是，保持滚动打开是有代价的，如 上一节，因此 scrolls 应该显式地 一旦不再使用滚动条，请使用 清除滚动应用程序接口：)
```json
DELETE /_search/scroll
{
  "scroll_id" : "DXF1ZXJ5QW5kRmV0Y2gBAAAAAAAAAD4WYm9laVYtZndUQlNsdDcwakFMNjU1QQ=="
}
```

